\documentclass[11pt]{article}

\usepackage{fullpage, verbatim, amsthm, amsmath, amssymb, amsfonts}

% Aliases
\newcommand{\K}{\mathcal{K}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\logbin}{\log_2}

% Setup page style
\parindent=0pt
\parskip=3mm

\theoremstyle{definition}
\newtheorem*{solution}{Solution}


\begin{document}

\begin{center}

  \bf \Large CPSC 418 / MATH 318 --- Introduction to Cryptography \\
  ASSIGNMENT 1

\end{center}


\medskip \hrule
  \textbf{Name:} Artem Golovin \\
  \textbf{Student ID:} 30018900
\medskip \hrule

% Problem 1
\item[] \textbf{Problem 1} --- Superencipherment for substitution ciphers, 12 marks

\begin{enumerate}
  \item
    \begin{enumerate}
      \item
        \begin{proof}
          Encryption using Shift cipher is given by $E_K (M) &\equiv (M + K) \mod 26$. Given $\M = \C = \K = \Z_{26}$, $K_1, K_2 \in \K$ and $M \in \M$: \\
          Let $C_1 \in \C$ be a ciphertext that results from encrypting plaintext $M$ with a key $K_1$:
          \begin{enumerate}
            \item $ E_{K_1}(M) &\equiv (M + K_1) \mod 26 $
            \item $ C_1 &\equiv E_{K_1} $
            \item $ C_1 &\equiv (M + K_1) \mod 26 $
            \item Let $C_2 = E_{K_2}(C_1)$, where $E_{K_2}(C_1) &\equiv (C_1 + K_2) \mod 26$
            \item Therefore, by substituting $C_1$,
              \begin{equation*}
              \begin{aligned}
                C_2 &= C_1 + K_2       &\pmod {26} \\
                    &= M + (K_1 + K_2) &\pmod {26} \\
                    &= M + K_3         &\pmod {26}
              \end{aligned}
              \end{equation*}
              Where $K_3 \in \K$ and $K_3 = K_1 + K_2$. Therefore, resulting key of multiple encipherment is $K_3$.
          \end{enumerate}
        \end{proof}

      \item
        \begin{proof}
          Based on previous proof, superencipherment using shift cipher can be defined as follows
          \[
            E_{K_i}(M) = (M + \sum_{\substack{k_i \in \k \\ i = 1}}^n k_i) \pmod {26}
          \]
          Where $M \in \M$, $K_i \in \K$, $n \in \Z$, and $i \geq 1, i \in \Z$.
          \begin{enumerate}
            \item
              Base Case: let $n = 1$,
              \begin{equation} \label{eq:p1_base_case}
              \begin{aligned}
                C &= M + \sum_{\substack{K_i \in \K \\ i = 1}}^1 K_i &\pmod {26} \\
                  &= M + K_1 &\pmod {26}
              \end{aligned}
              \end{equation}
            \item
              Induction hypothesis: Assume $n = m$, where $m \in \Z$. Therefore:
              \[
                C &= M + \sum_{\substack{K_i \in \K \\ i = 1}}^m K_i \pmod {26}
              \]

              Let: \\
              \begin{equation} \label{eq:p1_induction_hyp}
              \begin{aligned}
                K^{'} &= \sum^m_{\substack{K_i \in \K \\ i = 1}} K_i \\
                C &= M + K^{'} \pmod {26}
              \end{aligned}
              \end{equation}
              Still results in a shift cipher, according to definition.
            \item
              Inductive case: According to induction hypothesis, we can show that $m + 1$ holds true as well:
              \begin{align*}
                C &= (M + \sum^{m + 1}_{\substack{K_i \in \K \\ i = 1}} K_i) &\pmod {26} \\
                  &= (M + (\sum^{m}_{\substack{K_i \in \K \\ i = 1}} K_i + \sum^{1}_{\substack{K_i \in \K \\ i = 1}} K_i)) &\pmod {26} \\
                  &= (M + (\sum^{m}_{\substack{K_i \in \K \\ i = 1}} K_i + K_1)) &\pmod {26} \\
                  &= (M + (K^{'} + K_1)) &\pmod {26} \\
                  &= (M + K^{"}) &\pmod {26} \\
              \end{align*}
              where $K_1$ is our base case \eqref{eq:p1_base_case} and $K^{'}$ is our induction hypothesis \eqref{eq:p1_induction_hyp}. Since $K_1 \in \K$ and $K^{'} \in \K$, therefore $K^{"} = K_1 + K^{'}, K^{"} \in \K$. Hence, the key of multiple encipherment is sum of all given keys.
          \end{enumerate}
        \end{proof}
    \end{enumerate}

  \item
    \begin{proof}
      Let $M \in \M$ be a plaintext of length $x \in \Z$. Let $p_0, p_1, p_2, ...,p_{x - 1}$ be positions of letters in plaintext $M$. Given key $w_1 \in \K$ of length $m \in \Z$ and key $w_2 \in \K$ of length $n \in \Z$, let $k_0, k_1, k_2, ...,k_{m - 1}$ be positions of letters in key $w_1$, and $l_0, l_1, l_2, ...,l_{n - 1}$ be positions of letters in key $w_2$. To encrypt plaintext $p_i$, we use a key $k_j$, where $i$ is letter position from $0$ to $x - 1$.
      \[
        j \equiv i \pmod m
      \]
      Let ciphertext $C_i$ be ciphertext that corresponds to $p_i$
      \[
        C_i \equiv p_i + k_j \pmod {26}
      \]
      Where $k_j \equiv i \pmod m$. \\
      Let ciphertext $C_{2_i}$ be ciphertext that corresponds to $C_i$. Therefore, the second round of encryption, using the key $w_2$, results in following:
      \begin{equation*}
      \begin{aligned}
        C_{2_i} &= C_i + l_j &\pmod {26} \\
                &= (p_i + k_j) + l_z &\pmod {26} \\
                &= p_i + (k_j + l_z) &\pmod {26}
      \end{aligned}
      \end{equation*}
      Where $z \equiv i \pmod n$ and $l_z \equiv i \pmod n$. Therefore that ensures that length of resulting key will be $x$.
    \end{proof}
\end{enumerate}

\newpage

\item[] \textbf{Problem 2} --- Key size versus password size, 21 marks
\begin{enumerate}
  \item $256^8$
  
  \item 
    \begin{enumerate}
      \item $94^8$
      \item $\frac{94^8}{256^8} \times 100 \approx 0.033\%$
    \end{enumerate}
  
  \item
    Assuming that all characters are chosen equally likely, then $p(X_i) = \frac{1}{94}$. Therefore, entropy of the key space will be:
    \begin{equation*}
    \begin{aligned}
      H(X) &= 8 \times \frac{1}{94}\logbin 94 \\
           &\approx 0.56
    \end{aligned}
    \end{equation*}

  \item
    \begin{equation*}
    \begin{aligned}
      H(X) &= 8 \times \frac{1}{26}\logbin {\frac{1}{26} \\
           &\approx 1.45
    \end{aligned}
    \end{equation*}

  \item
    \begin{enumerate}
      Given $H(X) = 128$, let $n \in \Z$ be a password length.
      \item
        $p(X) = \frac{1}{94}$
        \begin{equation*}
        \begin{aligned}
          n \times \frac{1}{94}\logbin (94) = 128 \\
          n = \frac{128 \times 94}{\logbin (94)} \\
          n \approx 1836 
        \end{aligned}
        \end{equation*}
      
      \item
        $p(X) = \frac{1}{26}$
        \begin{equation*}
        \begin{aligned}
          n \times \frac{1}{26}\logbin (26) = 128 \\
          n = \frac{128 \times 26}{\logbin (26)} \\
          n \approx 709
        \end{aligned}
        \end{equation*}
    \end{enumerate}

\end{enumerate}
\newpage

\item[] \textbf{Problem 3} --- Equiprobability maximizes entropy for two outcomes, 12 marks
\begin{enumerate}
  \item
    \begin{equation*}
    \begin{aligned}
      H(X) &= \frac{1}{4}\logbin 4 + \frac{3}{4}\logbin {\frac{4}{3}} \\
           &\approx 0.811
    \end{aligned}
    \end{equation*}
  \item
    $H(X)$ is maximized if and only if all outcomes are equally likely. For any $n$, $H(X) = \logbin n$ is maximal if and only if $p(X_i) = \frac{1}{n}$ for $1 \leq i \leq n$.
    \begin{proof}
      Let's consider function $H(X) = p\logbin (\frac{1}{p}) + (1 - p)\logbin (\frac{1}{(1 - p)}) = -p\logbin p - (1 - p)\logbin (1 - p)$ as a function of $p$:
      \begin{equation*}
      \begin{aligned}
        H(p) &= p\logbin (\frac{1}{p}) + (1 - p)\logbin (\frac{1}{(1 - p)}) \\
             &= -p\logbin p - (1 - p)\logbin (1 - p)
      \end{aligned}
      \end{equation*}

      By taking the derivative of $H(p)$, we can determine maximum of the function
      \begin{equation*}
      \begin{aligned}
        H'(p) &= (-p\logbin p)' - ((1 - p)\logbin (1 - p)) \\
              &= -\frac{\ln (p) + 1}{\ln(2)} + \frac{\ln(1 - p) + 1}{\ln (2)} \\
              &= \frac{\ln (1 - p) - \ln (p)}{\ln (2)} \\
              &= \logbin (1-p) - \logbin (p)
      \end{aligned}
      \end{equation*}

      Maximum of $H'(p) = \logbin (1-p) - \logbin (p)$:
      \begin{equation*}
      \begin{aligned}
        \logbin (1-p) - \logbin (p) &= 0 \\
        \logbin (\frac{(1 - p)}{p}) &= 0 \\
        1 &= \frac{(1 - p)}{p} \\
        p &= 1 - p \\
        p &= \frac{1}{2} \\
      \end{aligned}
      \end{equation*}

    \end{proof}
  \item
    Maximal value of $H(X)$, given $p = \frac{1}{2}$:
    \begin{equation*}
    \begin{aligned}
      H(X) &= -\frac{1}{2}\logbin (\frac{1}{2}) - (1 - \frac{1}{2})\logbin (1 - \frac{1}{2}) \\
           &= \frac{1}{2} + \frac{1}{2} \\
           &= 1
    \end{aligned}
    \end{equation*}
\end{enumerate}

\item[] \textbf{Problem 4} --- Conditional entropy, 12 marks
\begin{enumerate}
  \item
    Given conditional entropy
    \[
      H(X|Y) = \sum_{y \in Y}\sum_{x \in X}p(x, y)\logbin (\frac{1}{p(x|y)})
    \]
    Where $p(x|y) \neq 0$, and $p(M_i) = p(C_i) = \frac{1}{4}$ for $1 \leq i,j \leq 4$, the resulting $H(\M|\C)$ is:
    \begin{equation*}
    \begin{aligned}
      H(\M|\C) &= \sum_{C \in \C}\sum_{M \in \M}p(M, C)\logbin (\frac{1}{p(M|C)}) \\
               &= 
    \end{aligned}
    \end{equation*}
  \item
  \item
\end{enumerate}

\end{document}
